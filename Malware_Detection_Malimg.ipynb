{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "Malware Detection Malimg ",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nalsadi/MalwareMalimgDetect/blob/master/Malware_Detection_Malimg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uria_HHzoGF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras \n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knjbVN7-obnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = np.load('/content/malimg.npz',allow_pickle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNV9eGoxo7PD",
        "colab_type": "code",
        "outputId": "556515d9-f893-415c-d122-052916ed167f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "BATCH_SIZE = 256 \n",
        "CELL_SIZE = 256 \n",
        "DROPOUT_RATE = 0.85 \n",
        "LEARNING_RATE = 1e-3 \n",
        "NODE_SIZE = [512, 256, 128] \n",
        "NUM_LAYERS = 5\n",
        "\n",
        "features = dataset['arr'][:, 0]\n",
        "features = np.array([feature for feature in features])\n",
        "features = np.reshape(features, (features.shape[0], features.shape[1] * features.shape[2]))\n",
        "r, c = features.shape\n",
        "\n",
        "print(\"Number of Samples\" , r)\n",
        "print(\"Number of Features\" , c)\n",
        "\n",
        "if 1==1:\n",
        "    features = StandardScaler().fit_transform(features)\n",
        "\n",
        "    \n",
        "labels = dataset['arr'][:, 1]\n",
        "labels = np.array([label for label in labels])\n",
        "\n",
        "\n",
        "labelio = labels\n",
        "print(labelio.shape,\"hjjhj\")\n",
        "\n",
        "one_hot = np.zeros((labels.shape[0], labels.max() + 1))\n",
        "one_hot[np.arange(labels.shape[0]), labels] = 1\n",
        "labels = one_hot\n",
        "labels[labels == 0] = 0\n",
        "num_features = features.shape[1]\n",
        "num_classes = labels.shape[1]\n",
        "\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.10,\n",
        "                                                                                stratify=labels)\n",
        "\n",
        "train_size = int(train_features.shape[0])\n",
        "train_features = train_features[:train_size-(train_size % BATCH_SIZE)]\n",
        "train_labels = train_labels[:train_size-(train_size % BATCH_SIZE)]\n",
        "\n",
        "test_size = int(test_features.shape[0])\n",
        "test_features = test_features[:test_size - (test_size % BATCH_SIZE)]\n",
        "test_labels = test_labels[:test_size - (test_size % BATCH_SIZE)]\n",
        "\n",
        "\n",
        "y1_train = keras.utils.to_categorical(train_labels, num_classes)\n",
        "y1_test = keras.utils.to_categorical(test_labels, num_classes)\n",
        "\n",
        "print(\"nsjnfjkdfass\", y1_train.shape)\n",
        "\n",
        "\n",
        "r, c = train_features.shape\n",
        "print(\"Number of Training Samples\" , r)\n",
        "print(\"Number of Training Features\" , c)\n",
        "\n",
        "r, c = test_features.shape\n",
        "print(\"Number of Test Samples\" , r)\n",
        "print(\"Number of Test Features\" , c)\n",
        "print(train_labels.shape)\n",
        "\n",
        "print(tf.reshape(test_features[1], [32,32]))\n",
        "from keras import backend as K\n",
        "\n",
        "#xtrain = tf.Session().run(train_features)\n",
        "#xtrain = K.eval(train_features)\n",
        "\n",
        "#xtest = tf.Session().run(test_features)\n",
        "\n",
        "\n",
        "print(train_features.shape,test_features.shape, train_labels.shape, test_labels.shape )\n",
        "\n",
        "print(train_labels)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Samples 9339\n",
            "Number of Features 1024\n",
            "(9339,) hjjhj\n",
            "nsjnfjkdfass (8192, 25, 25)\n",
            "Number of Training Samples 8192\n",
            "Number of Training Features 1024\n",
            "Number of Test Samples 768\n",
            "Number of Test Features 1024\n",
            "(8192, 25)\n",
            "Tensor(\"Reshape_7:0\", shape=(32, 32), dtype=float64)\n",
            "(8192, 1024) (768, 1024) (8192, 25) (768, 25)\n",
            "[[0. 0. 1. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sCIo80sTqxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential,Input,Model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "  \n",
        "  \n",
        "train_X = train_features.reshape(-1, 32,32, 1)\n",
        "test_X = test_features.reshape(-1, 32,32, 1)  \n",
        "\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "num_classes = 25\n",
        "\n",
        "input_shape = (32, 32, 1)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRuTA5kyUcxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PcOuV-HUeSY",
        "colab_type": "code",
        "outputId": "4cdc449f-0924-4ab2-87cc-4b2d2d367d31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        }
      },
      "source": [
        "print(train_labels)\n",
        "print(test_labels)\n",
        "\n",
        "model.fit(train_X, train_labels, batch_size=batch_size,epochs=20,verbose=1,validation_data=(test_X, test_labels))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 1. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n",
            "Train on 8192 samples, validate on 768 samples\n",
            "Epoch 1/20\n",
            "8192/8192 [==============================] - 3s 336us/step - loss: 1.4694 - acc: 0.5607 - val_loss: 0.7092 - val_acc: 0.7057\n",
            "Epoch 2/20\n",
            "8192/8192 [==============================] - 2s 242us/step - loss: 0.7721 - acc: 0.7487 - val_loss: 0.4909 - val_acc: 0.8242\n",
            "Epoch 3/20\n",
            "8192/8192 [==============================] - 2s 239us/step - loss: 0.5470 - acc: 0.8142 - val_loss: 0.4136 - val_acc: 0.8424\n",
            "Epoch 4/20\n",
            "8192/8192 [==============================] - 2s 241us/step - loss: 0.4338 - acc: 0.8499 - val_loss: 0.3810 - val_acc: 0.8451\n",
            "Epoch 5/20\n",
            "8192/8192 [==============================] - 2s 242us/step - loss: 0.3595 - acc: 0.8730 - val_loss: 0.3851 - val_acc: 0.8490\n",
            "Epoch 6/20\n",
            "8192/8192 [==============================] - 2s 242us/step - loss: 0.2960 - acc: 0.8936 - val_loss: 0.3863 - val_acc: 0.8529\n",
            "Epoch 7/20\n",
            "8192/8192 [==============================] - 2s 239us/step - loss: 0.2489 - acc: 0.9132 - val_loss: 0.4100 - val_acc: 0.8646\n",
            "Epoch 8/20\n",
            "8192/8192 [==============================] - 2s 243us/step - loss: 0.2165 - acc: 0.9225 - val_loss: 0.3688 - val_acc: 0.8646\n",
            "Epoch 9/20\n",
            "8192/8192 [==============================] - 2s 241us/step - loss: 0.1919 - acc: 0.9286 - val_loss: 0.3802 - val_acc: 0.8620\n",
            "Epoch 10/20\n",
            "8192/8192 [==============================] - 2s 243us/step - loss: 0.1610 - acc: 0.9395 - val_loss: 0.3654 - val_acc: 0.8841\n",
            "Epoch 11/20\n",
            "8192/8192 [==============================] - 2s 239us/step - loss: 0.1515 - acc: 0.9445 - val_loss: 0.4436 - val_acc: 0.8802\n",
            "Epoch 12/20\n",
            "8192/8192 [==============================] - 2s 239us/step - loss: 0.1329 - acc: 0.9525 - val_loss: 0.4201 - val_acc: 0.8737\n",
            "Epoch 13/20\n",
            "8192/8192 [==============================] - 2s 239us/step - loss: 0.1321 - acc: 0.9520 - val_loss: 0.4565 - val_acc: 0.8776\n",
            "Epoch 14/20\n",
            "8192/8192 [==============================] - 2s 238us/step - loss: 0.1283 - acc: 0.9546 - val_loss: 0.3954 - val_acc: 0.8854\n",
            "Epoch 15/20\n",
            "8192/8192 [==============================] - 2s 240us/step - loss: 0.1168 - acc: 0.9573 - val_loss: 0.4539 - val_acc: 0.8672\n",
            "Epoch 16/20\n",
            "8192/8192 [==============================] - 2s 240us/step - loss: 0.1072 - acc: 0.9607 - val_loss: 0.4659 - val_acc: 0.8724\n",
            "Epoch 17/20\n",
            "8192/8192 [==============================] - 2s 243us/step - loss: 0.0970 - acc: 0.9644 - val_loss: 0.4410 - val_acc: 0.8763\n",
            "Epoch 18/20\n",
            "8192/8192 [==============================] - 2s 241us/step - loss: 0.0993 - acc: 0.9653 - val_loss: 0.4321 - val_acc: 0.8815\n",
            "Epoch 19/20\n",
            "8192/8192 [==============================] - 2s 240us/step - loss: 0.0918 - acc: 0.9664 - val_loss: 0.4532 - val_acc: 0.8828\n",
            "Epoch 20/20\n",
            "8192/8192 [==============================] - 2s 240us/step - loss: 0.0832 - acc: 0.9707 - val_loss: 0.4913 - val_acc: 0.8815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1b2ab984e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    }
  ]
}