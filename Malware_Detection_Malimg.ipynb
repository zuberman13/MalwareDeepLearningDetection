{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "Malware Detection Malimg",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nalsadi/MalwareMalimgDetect/blob/master/Malware_Detection_Malimg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1lCK3oajsi0",
        "colab_type": "text"
      },
      "source": [
        "# **Malware Classification Using Deep Learning**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbGYpeYhuwK2",
        "colab_type": "text"
      },
      "source": [
        "This notebook will attempt to utilze state of the art neural network architectures to further develop the accuracy achieved by researchers on this topic. Dataset information and network descriptions will be provided below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uria_HHzoGF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras \n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDbdA2Toi1mv",
        "colab_type": "code",
        "outputId": "0201841d-dd5b-447f-cddf-f44269c1a8e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIWyLUVQkAdW",
        "colab_type": "text"
      },
      "source": [
        "## **Dataset**\n",
        "The malware dataset was obtained courtsey of Vision Research Lab\n",
        "University of California, Santa Barbara "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knjbVN7-obnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = np.load('/location/of/malimg.npz',allow_pickle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNV9eGoxo7PD",
        "colab_type": "code",
        "outputId": "7aeb963a-2660-4b33-fa68-f10b0d8ea11e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "BATCH_SIZE = 256 \n",
        "CELL_SIZE = 256 \n",
        "DROPOUT_RATE = 0.85 \n",
        "LEARNING_RATE = 1e-3 \n",
        "NODE_SIZE = [512, 256, 128] \n",
        "NUM_LAYERS = 5\n",
        "\n",
        "features = dataset['arr'][:, 0]\n",
        "features = np.array([feature for feature in features])\n",
        "features = np.reshape(features, (features.shape[0], features.shape[1] * features.shape[2]))\n",
        "r, c = features.shape\n",
        "\n",
        "print(\"Number of Samples\" , r)\n",
        "print(\"Number of Features\" , c)\n",
        "\n",
        "if 1==1:\n",
        "    features = StandardScaler().fit_transform(features)\n",
        "\n",
        "    \n",
        "labels = dataset['arr'][:, 1]\n",
        "labels = np.array([label for label in labels])\n",
        "\n",
        "\n",
        "one_hot = np.zeros((labels.shape[0], labels.max() + 1))\n",
        "one_hot[np.arange(labels.shape[0]), labels] = 1\n",
        "labels = one_hot\n",
        "labels[labels == 0] = 0\n",
        "num_features = features.shape[1]\n",
        "num_classes = labels.shape[1]\n",
        "\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.10,\n",
        "                                                                                stratify=labels)\n",
        "\n",
        "train_size = int(train_features.shape[0])\n",
        "train_features = train_features[:train_size-(train_size % BATCH_SIZE)]\n",
        "train_labels = train_labels[:train_size-(train_size % BATCH_SIZE)]\n",
        "\n",
        "test_size = int(test_features.shape[0])\n",
        "test_features = test_features[:test_size - (test_size % BATCH_SIZE)]\n",
        "test_labels = test_labels[:test_size - (test_size % BATCH_SIZE)]\n",
        "\n",
        "\n",
        "\n",
        "r, c = train_features.shape\n",
        "print(\"Number of Training Samples\" , r)\n",
        "print(\"Number of Training Features\" , c)\n",
        "\n",
        "r, c = test_features.shape\n",
        "print(\"Number of Test Samples\" , r)\n",
        "print(\"Number of Test Features\" , c)\n",
        "print(train_labels.shape)\n",
        "\n",
        "print(tf.reshape(test_features[1], [32,32]))\n",
        "\n",
        "print(train_features.shape,test_features.shape, train_labels.shape, test_labels.shape )\n",
        "\n",
        "print(train_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Samples 9339\n",
            "Number of Features 1024\n",
            "(9339,) hjjhj\n",
            "Number of Training Samples 8192\n",
            "Number of Training Features 1024\n",
            "Number of Test Samples 768\n",
            "Number of Test Features 1024\n",
            "(8192, 25)\n",
            "Tensor(\"Reshape_1:0\", shape=(32, 32), dtype=float64)\n",
            "(8192, 1024) (768, 1024) (8192, 25) (768, 25)\n",
            "[[0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sCIo80sTqxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential,Input,Model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "  \n",
        "  \n",
        "train_X = train_features.reshape(-1, 32,32, 1)\n",
        "test_X = test_features.reshape(-1, 32,32, 1)  \n",
        "\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "num_classes = 25\n",
        "\n",
        "input_shape = (32, 32, 1)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRuTA5kyUcxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PcOuV-HUeSY",
        "colab_type": "code",
        "outputId": "c6d83067-c92a-4208-878c-c6c712d08b81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(train_labels)\n",
        "print(test_labels)\n",
        "\n",
        "model.fit(train_X, train_labels, batch_size=batch_size,epochs=20,verbose=1,validation_data=(test_X, test_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n",
            "[[0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "Train on 8192 samples, validate on 768 samples\n",
            "Epoch 1/20\n",
            "8192/8192 [==============================] - 3s 313us/step - loss: 1.2885 - acc: 0.6117 - val_loss: 0.6433 - val_acc: 0.7943\n",
            "Epoch 2/20\n",
            "8192/8192 [==============================] - 2s 243us/step - loss: 0.6311 - acc: 0.7850 - val_loss: 0.4731 - val_acc: 0.8242\n",
            "Epoch 3/20\n",
            "8192/8192 [==============================] - 2s 239us/step - loss: 0.4537 - acc: 0.8398 - val_loss: 0.4277 - val_acc: 0.8398\n",
            "Epoch 4/20\n",
            "8192/8192 [==============================] - 2s 231us/step - loss: 0.3543 - acc: 0.8730 - val_loss: 0.3694 - val_acc: 0.8555\n",
            "Epoch 5/20\n",
            "8192/8192 [==============================] - 2s 233us/step - loss: 0.2599 - acc: 0.9100 - val_loss: 0.3573 - val_acc: 0.8620\n",
            "Epoch 6/20\n",
            "8192/8192 [==============================] - 2s 238us/step - loss: 0.2197 - acc: 0.9210 - val_loss: 0.3597 - val_acc: 0.8581\n",
            "Epoch 7/20\n",
            "8192/8192 [==============================] - 2s 233us/step - loss: 0.1609 - acc: 0.9395 - val_loss: 0.3779 - val_acc: 0.8620\n",
            "Epoch 8/20\n",
            "8192/8192 [==============================] - 2s 235us/step - loss: 0.1221 - acc: 0.9586 - val_loss: 0.3494 - val_acc: 0.8672\n",
            "Epoch 9/20\n",
            "8192/8192 [==============================] - 2s 237us/step - loss: 0.1114 - acc: 0.9617 - val_loss: 0.3621 - val_acc: 0.8815\n",
            "Epoch 10/20\n",
            "8192/8192 [==============================] - 2s 234us/step - loss: 0.0927 - acc: 0.9685 - val_loss: 0.3514 - val_acc: 0.8893\n",
            "Epoch 11/20\n",
            "8192/8192 [==============================] - 2s 240us/step - loss: 0.0886 - acc: 0.9714 - val_loss: 0.4416 - val_acc: 0.8620\n",
            "Epoch 12/20\n",
            "8192/8192 [==============================] - 2s 237us/step - loss: 0.0799 - acc: 0.9728 - val_loss: 0.3916 - val_acc: 0.8854\n",
            "Epoch 13/20\n",
            "8192/8192 [==============================] - 2s 240us/step - loss: 0.0739 - acc: 0.9716 - val_loss: 0.4097 - val_acc: 0.8828\n",
            "Epoch 14/20\n",
            "8192/8192 [==============================] - 2s 232us/step - loss: 0.0627 - acc: 0.9780 - val_loss: 0.4714 - val_acc: 0.8789\n",
            "Epoch 15/20\n",
            "8192/8192 [==============================] - 2s 228us/step - loss: 0.0672 - acc: 0.9761 - val_loss: 0.4524 - val_acc: 0.8815\n",
            "Epoch 16/20\n",
            "8192/8192 [==============================] - 2s 240us/step - loss: 0.0552 - acc: 0.9801 - val_loss: 0.4798 - val_acc: 0.8672\n",
            "Epoch 17/20\n",
            "8192/8192 [==============================] - 2s 229us/step - loss: 0.0540 - acc: 0.9810 - val_loss: 0.4959 - val_acc: 0.8763\n",
            "Epoch 18/20\n",
            "8192/8192 [==============================] - 2s 239us/step - loss: 0.0565 - acc: 0.9801 - val_loss: 0.4793 - val_acc: 0.8750\n",
            "Epoch 19/20\n",
            "8192/8192 [==============================] - 2s 235us/step - loss: 0.0539 - acc: 0.9813 - val_loss: 0.5615 - val_acc: 0.8672\n",
            "Epoch 20/20\n",
            "8192/8192 [==============================] - 2s 236us/step - loss: 0.0513 - acc: 0.9818 - val_loss: 0.4739 - val_acc: 0.8737\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fadd00516a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jZUs4ndpajB",
        "colab_type": "code",
        "outputId": "3bf64e02-7037-4eb4-b5e7-2bc2875c0175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "ypred = model.predict(test_X,batch_size=256)\n",
        "print(test_labels.shape)\n",
        "print(ypred.shape)\n",
        "ypred=np.argmax(ypred, axis=1)\n",
        "test_labels = np.argmax(test_labels, axis=1)\n",
        "confusion_matrix(test_labels,ypred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(768, 25)\n",
            "(768, 25)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 10,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0, 220,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,  35,  96,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,  18,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,  10,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   4,   0,   0,   0,  11,   0,   0,   0,   1,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   5,   6,   0,   0,   0,   0,   0,\n",
              "          0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  11,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   1,   0,   0,   0,   0,   0,   0,   0,  26,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  36,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         15,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   9,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  13,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   5,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,  12,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,  13,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   8,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   4,   3,   0,   0,   0],\n",
              "       [  0,   0,   2,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   3,   5,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,  32,   0,   0],\n",
              "       [  0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   5,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  66]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5815d6b7-3ea9-434f-afce-70d41ef5629d",
        "id": "8Vf3OgQqth6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "class_names = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(test_labels, ypred, classes=labels, title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(test_labels, ypred, classes=labels, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b3df0a2fce09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# Plot non-normalized confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mypred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Confusion matrix, without normalization'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# Plot normalized confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_labels' is not defined"
          ]
        }
      ]
    }
  ]
}